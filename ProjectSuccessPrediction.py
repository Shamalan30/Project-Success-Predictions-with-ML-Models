# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cuUKD_kGU64cxDRrlm4ptU_GPu4hCLLa
"""

import pandas as pd
import io
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Import all the models we will use
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# --- 1. Load Expanded Data ---
csv_data = """Team_Experience_Years,Budget_USD_Thousands,Methodology,Risk_Score,Project_Success
8.5,250,Agile,3,1
3.2,120,Waterfall,7,0
10.1,300,Agile,2,1
5.5,180,Agile,5,1
2.1,90,Waterfall,8,0
4.8,150,Waterfall,6,0
7.9,230,Agile,4,1
6.2,200,Agile,4,1
1.5,80,Waterfall,9,0
9.8,280,Agile,2,1
12.0,350,Agile,1,1
4.1,130,Waterfall,7,0
3.9,160,Agile,6,0
6.8,210,Agile,5,1
2.8,110,Waterfall,8,0
7.5,220,Waterfall,4,1
11.2,320,Agile,2,1
5.1,190,Agile,5,0
1.9,100,Waterfall,9,0
8.8,260,Agile,3,1
4.5,140,Waterfall,7,0
9.2,290,Agile,3,1
3.5,145,Waterfall,6,0
6.5,205,Agile,5,1
2.5,95,Waterfall,8,0
10.5,310,Agile,2,1
5.8,170,Waterfall,5,1
2.2,85,Waterfall,9,0
7.1,240,Agile,4,1
4.9,165,Agile,6,0
8.2,270,Waterfall,3,1
11.8,340,Agile,1,1
3.1,115,Waterfall,8,0
6.0,195,Agile,5,0
9.5,275,Agile,3,1
2.9,105,Waterfall,7,0
7.8,235,Agile,4,1
5.3,175,Waterfall,6,1
1.7,75,Waterfall,9,0
8.6,255,Agile,3,1
6.1,185,Agile,6,0
7.3,215,Waterfall,5,1
3.3,125,Agile,7,0
9.0,265,Agile,4,1
4.3,135,Waterfall,7,0
10.8,315,Agile,2,1
2.7,98,Waterfall,8,0
8.1,245,Agile,3,1
5.6,178,Waterfall,6,1
3.8,155,Agile,7,0
11.5,330,Agile,1,1
2.4,92,Waterfall,9,0
7.0,225,Agile,5,1
4.7,152,Waterfall,6,0
9.9,285,Agile,3,1
5.9,198,Agile,5,0
10.3,305,Waterfall,2,1
3.6,128,Waterfall,7,0
8.4,258,Agile,4,1
6.7,208,Waterfall,5,1
"""
df = pd.read_csv(io.StringIO(csv_data))

# --- 2. Preprocessing ---
X = df.drop('Project_Success', axis=1)
y = df['Project_Success']
X = pd.get_dummies(X, columns=['Methodology'], drop_first=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


# --- 3. Define 15 Model Configurations ---
model_definitions = [
    # K-Nearest Neighbors (varying neighbors)
    {"id": "knn_01", "name": "KNN (k=1)", "model": KNeighborsClassifier(n_neighbors=1)},
    {"id": "knn_02", "name": "KNN (k=3)", "model": KNeighborsClassifier(n_neighbors=3)},
    {"id": "knn_03", "name": "KNN (k=7)", "model": KNeighborsClassifier(n_neighbors=7)},

    # Decision Trees (varying max depth to control complexity)
    {"id": "dt_01", "name": "Decision Tree (depth=2)", "model": DecisionTreeClassifier(max_depth=2, random_state=42)},
    {"id": "dt_02", "name": "Decision Tree (depth=4)", "model": DecisionTreeClassifier(max_depth=4, random_state=42)},
    {"id": "dt_03", "name": "Decision Tree (unlimited depth)", "model": DecisionTreeClassifier(random_state=42)},

    # Logistic Regression (varying regularization strength)
    {"id": "lr_01", "name": "Logistic Regression (C=0.1)", "model": LogisticRegression(C=0.1, random_state=42)},
    {"id": "lr_02", "name": "Logistic Regression (C=1.0)", "model": LogisticRegression(C=1.0, random_state=42)},

    # Support Vector Machines (varying kernel and C)
    {"id": "svm_01", "name": "SVM (linear, C=1.0)", "model": SVC(kernel='linear', C=1.0, random_state=42)},
    {"id": "svm_02", "name": "SVM (rbf, C=1.0)", "model": SVC(kernel='rbf', C=1.0, random_state=42)},
    {"id": "svm_03", "name": "SVM (rbf, C=10.0)", "model": SVC(kernel='rbf', C=10.0, random_state=42)},

    # Random Forest (varying number of trees and depth)
    {"id": "rf_01", "name": "Random Forest (10 trees, depth=3)", "model": RandomForestClassifier(n_estimators=10, max_depth=3, random_state=42)},
    {"id": "rf_02", "name": "Random Forest (50 trees, depth=3)", "model": RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)},
    {"id": "rf_03", "name": "Random Forest (50 trees, unlimited depth)", "model": RandomForestClassifier(n_estimators=50, random_state=42)},
    {"id": "rf_04", "name": "Random Forest (100 trees, unlimited depth)", "model": RandomForestClassifier(n_estimators=100, random_state=42)},
]

# --- 4. Train, Evaluate, and Store Results ---
results = []
for config in model_definitions:
    model = config["model"]
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)

    results.append({
        "Model ID": config["id"],
        "Algorithm & Configuration": config["name"],
        "Accuracy": acc
    })

# --- 5. Display Final Table ---
results_df = pd.DataFrame(results).sort_values(by="Accuracy", ascending=False).reset_index(drop=True)
print("--- Final Model Performance Results (Sorted by Accuracy) ---")
print(results_df.to_string())
results_df.to_csv("model_performance_results.csv", index=False)
